{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e29eed3f-29dc-4048-972d-caca5f5e8a0e",
   "metadata": {},
   "source": [
    "# Intuition Behind Artificial Neural Networks\n",
    "\n",
    "2022 DS Elective 4 <br>\n",
    "University of Science and Technology of the Philippines <br>\n",
    "Instructor: Jhun Brian M. Andam <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f90eff-d478-4b42-9371-fd2da947a629",
   "metadata": {},
   "source": [
    "## Example:\n",
    "\n",
    "<center><img src=\"nn.png\" width=\"400\"></center>\n",
    "\n",
    "Assume that the neurons have a `sigmoid` activation function, perform a forward pass on the network. Assume that the actual output of $y$ is 1 and `learning rate` $\\alpha$ is 0.9. Perform another forward pass.\n",
    "\n",
    "$$x = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "$$y = \\begin{bmatrix} 1 \\end{bmatrix}$$\n",
    "\n",
    "$$\\text{hidden unit weights} = \n",
    "\\begin{bmatrix}\n",
    "w_{11} = 0.2 && w_{12} = -0.3 \\\\\n",
    "w_{13} = 0.4 && w_{14} = 0.1 \\\\\n",
    "w_{15} = -0.5 && w_{16} = 0.2\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$\\text{output unit weights} = \n",
    "\\begin{bmatrix}\n",
    "w_{21} = -0.3 \\\\\n",
    "w_{22} = -0.2\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$\\theta = \n",
    "\\begin{bmatrix}\n",
    "\\theta_{1} = -0.4 \\\\\n",
    "\\theta_{2} = 0.2 \\\\\n",
    "\\theta_{3} = 0.1\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cff204-0fe0-4227-b5a3-193d9503e881",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "\n",
    "To calculate $H_1$, we need to calculate first the weighted sum of the input values added by the bias $\\theta$.\n",
    "\n",
    "## $$Z = \\sum_j{(w_{i,j} \\cdot x_i)} + \\theta_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ef0ff-3f3d-4362-9027-53819d8e7cb0",
   "metadata": {},
   "source": [
    "### $Z_1 = w_{11} \\cdot x_1 + w_{13} \\cdot x_2 + w_{15} \\cdot x_3 + \\theta_1$\n",
    "\n",
    "### $Z_1 = (0.2 \\cdot 1) + (0.4 \\cdot 0) + (-0.5 \\cdot 1) + (-0.4)$\n",
    "\n",
    "### $Z_1 = -0.7$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4b437-9fc5-42c8-80c3-7a6e3d1fcf9e",
   "metadata": {},
   "source": [
    "Now we introduce `non-linearity` by applying the sigmoid function $\\sigma$.\n",
    "\n",
    "## $$\\sigma = \\frac{1}{1+e^{-Z_i}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c267a5-c0e1-4830-92bb-16235d1c3cf1",
   "metadata": {},
   "source": [
    "### $H_1 = \\frac{1}{1+e^{-(-0.7)}}$\n",
    "\n",
    "### $H_1 = 0.332$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a56b14-acf1-4804-9404-f9b4ef96be64",
   "metadata": {},
   "source": [
    "Similarly, we have to calculate the value for $H_2$ using the same procedures.\n",
    "\n",
    "### $Z_2 = w_{12} \\cdot x_1 + w_{14} \\cdot x_2 + w_{16} \\cdot x_3 + \\theta_2$\n",
    "\n",
    "### $Z_2 = (-0.3 \\cdot 1) + (0.1 \\cdot 0) + (0.2 \\cdot 1) + (0.2)$\n",
    "\n",
    "### $Z_2 = 0.1$\n",
    "\n",
    "Apply the activation function $\\sigma$\n",
    "\n",
    "### $H_2 = \\frac{1}{1+e^{-0.1}}$\n",
    "\n",
    "### $H_2 = 0.525$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184ce26b-3f1f-41e4-ad10-d4b2dfaf9393",
   "metadata": {},
   "source": [
    "The same procedure is followed to calculate the value for the $\\hat{y}$\n",
    "\n",
    "\n",
    "### $Z_3 = w_{21} \\cdot H_1 + w_{22} \\cdot H_2 + \\theta_3$\n",
    "\n",
    "### $Z_3 = (-0.3 \\cdot 0.332) + (0.1 \\cdot 0.525) + (0.1)$\n",
    "\n",
    "### $Z_3 = -0.105$\n",
    "\n",
    "Apply the activation function $\\sigma$\n",
    "\n",
    "### $\\hat{y} = \\frac{1}{1+e^{-(-0.105)}}$\n",
    "\n",
    "### $\\hat{y} = 0.474$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6557162-5c12-4775-b096-c39fb999ab74",
   "metadata": {},
   "source": [
    "Now that we have calculated the predicted output $\\hat{y}$, we can now determine how much error did our model have using the initial weights that we used. To do that, we have to calculate the loss by using a loss function. Assume that our error function is just the difference between the target output and the predicted output.\n",
    "\n",
    "## $$Error = y - \\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b4b41-60e9-42a2-9007-f895fd162dad",
   "metadata": {},
   "source": [
    "$Error = 1-0.474$\n",
    "\n",
    "$Error = 0.526$\n",
    "\n",
    "The ideal error value is 0 or even close to zero, in order to minimize this error, we do an optimization called gradient descent. This optimization function minimizes the error by backpropagating and updating each parameters $(w, \\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6534d-9da8-48ad-80c0-3dd133f5b477",
   "metadata": {},
   "source": [
    "## Backward Propagation\n",
    "\n",
    "Each weight is updated using:\n",
    "\n",
    "## $$\\Delta{w_{ji}} = \\alpha \\delta_j O_i$$\n",
    "\n",
    "$$\\delta_j = \\begin{cases}\n",
    "O_j(1-O_j)(t_j - O_j) && \\text{if $j$ is an output unit} \\\\\n",
    "O_j(1-O_j)\\sum_k{\\delta_k w_{kj}} && \\text{if $j$ is a hidden unit}\n",
    "\\end{cases}$$\n",
    "\n",
    "<br></br>\n",
    "\n",
    "Where: \n",
    "\n",
    "* $O$ is the output of the neuron after the activation function is applied.\n",
    "* $\\alpha$ is the learning rate $(0.9)$\n",
    "* $\\delta_j$ is the error measure for unit $j$\n",
    "* $t_j$ is the correct output for unit $j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe00333-0400-4a7a-9b2e-1f02ae326633",
   "metadata": {},
   "source": [
    "Calculating the error term for the output $(\\hat{y})$ , since $\\hat{y}$ is calculated using the output unit weights, we can calculate the $\\delta$ using the equation..\n",
    "\n",
    "### $\\delta_3 = \\hat{y}(1-\\hat{y}) (y - \\hat{y})$\n",
    "\n",
    "### $\\delta_3 = 0.474 \\cdot (1 - 0.474) \\cdot (1 - 0.474)$\n",
    "\n",
    "### $\\delta_3 = 0.1311$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ba9f4-f3b0-45a5-9ab5-e0f44a97ceaf",
   "metadata": {},
   "source": [
    "Calculating the error term for the $\\delta_2$ is different since it belongs to the hiddenlayer unit.\n",
    "\n",
    "### $\\delta_2 = H_2 (1-H_2) w_{22} \\cdot \\delta_3$\n",
    "\n",
    "### $\\delta_2 = 0.525 (1-0.525) \\cdot (-0.2 \\cdot 0.1311) $\n",
    "\n",
    "### $\\delta_2 = -0.0065$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d4239-0f66-40b4-8e52-1f0e852fa3de",
   "metadata": {},
   "source": [
    "The same procedure goes with $\\delta_1$\n",
    "\n",
    "### $\\delta_1 = H_1 (1-H_1) w_{21} \\cdot \\delta_3$\n",
    "\n",
    "### $\\delta_1 = 0.332 (1-0.332) \\cdot (-0.3 \\cdot 0.1311) $\n",
    "\n",
    "### $\\delta_1 = -0.0087$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff9a5a-1b5f-49bd-a153-35f51c808bd3",
   "metadata": {},
   "source": [
    "Now that we have our $\\delta_j$ values, we can now calculate the rate of change of our parameters.\n",
    "\n",
    "$$\\delta = \n",
    "\\begin{bmatrix} \n",
    "\\delta_1 = -0.0087 \\\\ \n",
    "\\delta_2 = -0.0065 \\\\\n",
    "\\delta_3 = 0.1311 \n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1cf18-d693-4f7e-9dd6-67a822e0fea1",
   "metadata": {},
   "source": [
    "Let's calculate the rate of change of $w_{21}.$\n",
    "\n",
    "### $\\Delta w_{21} = \\alpha \\delta_3 H_1$\n",
    "\n",
    "### $\\Delta w_{21} = 0.9 \\cdot 0.1311 \\cdot 0.332$\n",
    "\n",
    "### $\\Delta w_{21} = 0.0392$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82011b9-3408-426a-a601-c6d8015aad12",
   "metadata": {},
   "source": [
    "Finally, we can update the $w_{21}$ by adding the rate of change of the weight $\\Delta w_{21}$ and the inital value of the weight $w_{21}$.\n",
    "\n",
    "### $w_{21 \\ (new)} = \\Delta w_{21} + w_{21}$\n",
    "\n",
    "### $w_{21 \\ new} = 0.0392 + (-0.3)$\n",
    "\n",
    "### $w_{21 \\ new} = -0.261$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5730729-4490-411a-8530-8bacb12a9a38",
   "metadata": {},
   "source": [
    "Calculating the rate of change for a hidden unit weight looks something like this. We take into account the value of the input $x$.\n",
    "\n",
    "### $\\Delta w_{11} = \\alpha \\delta_1 x_1$\n",
    "\n",
    "### $\\Delta w_{11} = 0.9 (-0.0087) \\cdot 1$\n",
    "\n",
    "### $\\Delta w_{11} = -0.0078$\n",
    "\n",
    "### $w_{11 \\ (new)} = \\Delta w_{11} + w_{11}$\n",
    "\n",
    "### $w_{11 \\ new} = -0.0078 + 0.2$\n",
    "\n",
    "### $w_{11 \\ new} = 0.192$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9f3ae-8fa7-4b27-8e41-64ce8c6e604c",
   "metadata": {},
   "source": [
    "Similarly, we can calculate the rate of change for the bias $(\\theta)$ to update the parameter.\n",
    "\n",
    "### $\\Delta \\theta_3 = \\alpha \\delta_3$\n",
    "\n",
    "### $\\Delta \\theta_3 = 0.9 \\cdot 0.1311$\n",
    "\n",
    "### $\\Delta \\theta_3 = 0.11799$\n",
    "\n",
    "### $\\theta_{3 \\ new} = \\Delta \\theta_3 + \\theta_3$\n",
    "\n",
    "### $\\theta_{3 \\ new} = 0.218$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
